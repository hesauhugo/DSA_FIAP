## Tutorial do spark no R
* seguir o link abaixo
* <a href="https://amunategui.github.io/sparkr/">Spark</a>
* Após criado acesse o endpoint
* Abra o shell no rstudio e procure o arquivo `.pem`
* Em seguida execute o comando
    ```ps
        ssh -i spark.pem ec2-user@[coloque_o_ip_publico_aqui]
    ```
* Definir chaves de criptografia
* Realizar criação do cluster do spark
* Serão criados mestres e scravos
* Voltar ao console EC2 
* Acessa o mestre e cria o usuario
* Fazer login em uma máquina
* Após isso realiza  a configuração dos clusters
* Inicializar a aplicação dentro do spark
* Fazer um teste passando uma base para o cluster e executando o comandos head()

## Spark Hand-ON
* Opensource
* Evolução do Hadoop
* Hadoop = discos x Spark = memoria
* Universidade de Barckley
* Spark faz uso do Hadoop
* Spark é standalone
* Spark SQL
* Spark Streamming
* GraphX
* Spark MLLib
* Escala é a linguagem nativa
* Python com pyspark
* Java tem uma biblioteca comunicar com spark
* <a href="https://cognitiveclass.ai/courses">Cognitive Class</a>
